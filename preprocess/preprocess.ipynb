{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# 文件夹\n",
    "##############\n",
    "# 文件夹\n",
    "bpseq_old_folder = './bpseqFiles/bpseqFiles'\n",
    "sta_old_folder = './staFiles/staFiles'\n",
    "\n",
    "bpseq_dbn_new_folder = '../data/dbn_bpseqFiles/'\n",
    "bpseq_flag_new_folder = '../data/flag_bpseqFiles/'\n",
    "bpseq_test_new_folder = '../data/bpseqFiles/'\n",
    "\n",
    "# 文件\n",
    "### dbn_output_forge_file 归并\n",
    "# stem_tab_file 表文件\n",
    "# dbn_output_forge_file = './data/rna.dbn.txt'\n",
    "# flag_output_forge_file = './data/rna.flag.txt'\n",
    "\n",
    "#############\n",
    "# 写表文件\n",
    "stem_tab_file = '../table/stem.txt'\n",
    "dbn_tab_file = '../table/dbn.txt'\n",
    "flag_tab_file = '../table/flag.txt'\n",
    "#\n",
    "#############\n",
    "\n",
    "###############\n",
    "# 把所有文件写到以下的目录中\n",
    "train_folder = '../data/train/'\n",
    "test_folder = '../data/test/'\n",
    "vaild_folder = '../data/vaild/'\n",
    "\n",
    "dbn_file_in ='dbn.in.txt'\n",
    "dbn_file_out ='dbn.out.txt'\n",
    "\n",
    "flag_file_in ='flag.in.txt'\n",
    "flag_file_out = 'flag.out.txt'\n",
    "#\n",
    "#################\n",
    "\n",
    "if not os.path.exists(bpseq_dbn_new_folder):\n",
    "    os.makedirs(bpseq_dbn_new_folder)\n",
    "if not os.path.exists(bpseq_flag_new_folder):\n",
    "    os.makedirs(bpseq_flag_new_folder)\n",
    "    \n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "if not os.path.exists(test_folder):\n",
    "    os.makedirs(test_folder)\n",
    "if not os.path.exists(vaild_folder):\n",
    "    os.makedirs(vaild_folder)\n",
    "    \n",
    "if not os.path.exists(\"../table\"):\n",
    "    os.makedirs(\"../table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义的轮赌盘算法 作为数据分类的依据\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import random,pdb\n",
    "import operator\n",
    "\n",
    "weights=[20,20,60]\n",
    "\n",
    "def roulette_selection(weights):\n",
    "        '''performs weighted selection or roulette wheel selection on a list\n",
    "        and returns the index selected from the list'''\n",
    "\n",
    "        # sort the weights in ascending order\n",
    "        sorted_indexed_weights = sorted(enumerate(weights), key=operator.itemgetter(1));\n",
    "        indices, sorted_weights = zip(*sorted_indexed_weights);\n",
    "        # calculate the cumulative probability\n",
    "        tot_sum=sum(sorted_weights)\n",
    "        prob = [x/tot_sum for x in sorted_weights]\n",
    "        cum_prob=np.cumsum(prob)\n",
    "        # select a random a number in the range [0,1]\n",
    "        random_num=random.random()\n",
    "\n",
    "        for index_value, cum_prob_value in zip(indices,cum_prob):\n",
    "            if random_num < cum_prob_value:\n",
    "                return index_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####引入进度条配置\n",
    "from progressbar import *               # just a simple progress bar\n",
    "##progressbar2的配置\n",
    "widgets = ['Running: ', Percentage(), ' ', Bar(marker='*',left='[',right=']'),\n",
    "           ' ', ETA(), ' ', FileTransferSpeed()] #see docs for other options\n",
    "pbar = ProgressBar(widgets=widgets)\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bpseqFiles/bpseqFiles\n",
      "读取文件夹... ['./bpseqFiles/bpseqFiles/bpRNA_CRW_32951.bpseq', './bpseqFiles/bpseqFiles/bpRNA_CRW_42904.bpseq']\n",
      "写文件夹... ['../data/dbn_bpseqFiles/bpRNA_CRW_32951.bpseq', '../data/dbn_bpseqFiles/bpRNA_CRW_42904.bpseq']\n",
      "写文件夹... ['../data/flag_bpseqFiles/bpRNA_CRW_32951.bpseq', '../data/flag_bpseqFiles/bpRNA_CRW_42904.bpseq']\n"
     ]
    }
   ],
   "source": [
    "####清理脏数据，并重新保存####\n",
    "#  \n",
    "# bpseq_old_files 是原来的文件\n",
    "# bpseq_dbn_new_files 修改之后的带括号的文件\n",
    "# bpseq_flag_new_files 修改之后 01 的文件\n",
    "bpseq_old_files=[] \n",
    "bpseq_dbn_new_files=[]\n",
    "bpseq_flag_new_files=[]\n",
    "\n",
    "for root, dirs, files in os.walk(bpseq_old_folder, topdown=False):\n",
    "    print(root)\n",
    "    bpseq_old_files =    [os.path.join(root, name) for name in files]\n",
    "    bpseq_dbn_new_files =  [os.path.join(bpseq_dbn_new_folder, name) for name in files]\n",
    "    bpseq_flag_new_files =  [os.path.join(bpseq_flag_new_folder, name) for name in files]\n",
    "    sta_files =              [os.path.join(sta_old_folder,name[:-6]+'.sta')for name in files]\n",
    "\n",
    "print(\"读取文件夹...\",bpseq_old_files[1:3])\n",
    "print(\"写文件夹...\",bpseq_dbn_new_files[1:3])\n",
    "print(\"写文件夹...\",bpseq_flag_new_files[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: N/A% [*                                     ] Time:  0:03:29 488.0 B/s\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar(widgets=widgets)\n",
    "for (old_file,sta_file,dbn_output_file,flag_output_file) in pbar(zip(bpseq_old_files,sta_files,bpseq_dbn_new_files,bpseq_flag_new_files)):# 保存文件名，碱基，序号，匹配号\n",
    "\n",
    "    with open(sta_file,'r') as fr:# 找到第一个可用的那一行数据\n",
    "        start_line_num = 0\n",
    "        dbn_line_offset = 1\n",
    "        sta_lines =fr.readlines()\n",
    "\n",
    "        while(sta_lines[start_line_num][0]=='#'):\n",
    "            start_line_num += 1\n",
    "        dbn_line = sta_lines[start_line_num + dbn_line_offset]\n",
    "    \n",
    "    with open(old_file,'r') as fr:\n",
    "        start_line_num = 0\n",
    "        dbn_new_lines  = ''\n",
    "        flag_new_lines  = ''\n",
    "        old_lines    = fr.readlines()\n",
    "        for idx,old_line in enumerate(old_lines):\n",
    "            if old_line[0]=='#':# 如果是文件注释\n",
    "                dbn_new_line = old_line\n",
    "                flag_new_line = old_line\n",
    "                dbn_new_lines+=dbn_new_line\n",
    "                flag_new_lines+=flag_new_line\n",
    "                start_line_num += 1\n",
    "            else:\n",
    "                order,base,match = old_line.strip('\\n').split(' ')\n",
    "\n",
    "                base = base.upper()\n",
    "                match_i = int(match)\n",
    "                dbn = ''\n",
    "                if base not in {'A','C','G','U'} and match_i>0:\n",
    "                    trg_order,trg_base,trg_match = old_lines[match_i+start_line_num-1].strip('\\n').split(' ')\n",
    "                    if trg_base == 'A':base = 'U'\n",
    "                    elif trg_base == 'C':base = 'G'\n",
    "                    elif trg_base == 'U':base = np.random.choice(['A','G'])\n",
    "                    elif trg_base == 'G':base = np.random.choice(['C','U'])\n",
    "                if int(match)>0:\n",
    "                    match_flag ='1'\n",
    "                    if order < match:dbn = '('\n",
    "                    else:dbn = ')'\n",
    "                else: \n",
    "                    match_flag = '0'\n",
    "                    dbn = '.'\n",
    "#                 dbn_new_line = order+' '+base+' '+match+' '+dbn_line[idx-start_line_num]+'\\n'  多种dbn 如果要使用请注释下一行\n",
    "                dbn_new_line = order+' '+base+' '+match+' '+dbn+'\\n'\n",
    "                flag_new_line = order+' '+base+' '+match+' '+match_flag+'\\n'\n",
    "                dbn_new_lines+=dbn_new_line\n",
    "                flag_new_lines+=flag_new_line\n",
    "    with open(dbn_output_file,'w') as fw1 :\n",
    "        fw1.writelines(dbn_new_lines)\n",
    "    with open(flag_output_file,'w') as fw2:\n",
    "        fw2.writelines(flag_new_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running: 100% [************************************] Time:  0:00:10   9.5 KiB/s\n",
      "Running: 100% [************************************] Time:  0:00:09  10.1 KiB/s\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "#将大量不同到碱基对，合并到一个文件中，并且将输入输出分开\n",
    "# 设置文件到上限和显现\n",
    "toplimit = 250\n",
    "downlimit = 100\n",
    "\n",
    "\n",
    "def save_to_one(bpseq_new_folder,output_file_in,output_file_out,toplimit,downlimit):\n",
    "    #将文件合并保存到output_file\n",
    "    for root, dirs, files in os.walk(bpseq_new_folder, topdown=False):\n",
    "        bpseq_files = [os.path.join(root, name) for name in files]\n",
    "\n",
    "    pbar = ProgressBar(widgets=widgets)\n",
    "    for file in pbar(bpseq_files):# 保存文件名，碱基，序号，匹配号\n",
    "        with open(file,'r') as fr:\n",
    "            lines = fr.readlines()\n",
    "            if len(lines)>toplimit or len(lines)<downlimit:\n",
    "                continue\n",
    "            file_name = fr.name.strip('\\n')\n",
    "            start = 0\n",
    "            file_info = 'None'\n",
    "            while lines[start][0] == '#':\n",
    "                start += 1\n",
    "            if start>0:\n",
    "                file_info = lines[start-1][1:].strip('\\n')\n",
    "            bases = ''\n",
    "            order_num = ''\n",
    "            match_num = ''\n",
    "            marks = ''\n",
    "            for line in lines[start:-1]:\n",
    "                try:\n",
    "                    order,base,match,mark = line.strip('\\n').split(' ')#顺序，碱基，匹配信息，dbn，匹配标志\n",
    "                except:\n",
    "                    print('[Error]: from %s in %s'%(file_name,line))\n",
    "                bases += base+' '\n",
    "                order_num += order+' '\n",
    "                match_num += match+' '\n",
    "                marks += mark+' '\n",
    "\n",
    "        # 轮盘算法 区分比例\n",
    "        weights=[15,15,70]\n",
    "        folder_class =  roulette_selection(weights)\n",
    "        if folder_class == 2:\n",
    "            folder = train_folder\n",
    "        elif folder_class == 1:\n",
    "            folder = vaild_folder\n",
    "        else:\n",
    "            folder = test_folder\n",
    "        \n",
    "        with open(folder + output_file_in,'a+') as fin:\n",
    "            _line=bases+'\\n'\n",
    "            fin.write(_line)\n",
    "        \n",
    "        with open(folder + output_file_out,'a+') as fout:\n",
    "            _line = marks+'\\n'\n",
    "            fout.write(_line)\n",
    "        \n",
    "            \n",
    "save_to_one(bpseq_dbn_new_folder,dbn_file_in,dbn_file_out,toplimit,downlimit)\n",
    "save_to_one(bpseq_flag_new_folder,flag_file_in,flag_file_out,toplimit,downlimit)\n",
    "# save_to_one(bpseq_dbn_new_folder,flag_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成词表文件\n",
    "from enum import Enum\n",
    "Type = Enum(\"Type\",(\"feature\",\"label\"))\n",
    "def generate_stem_file(input_seg_file,output_stem_file,model):\n",
    "    #生产词表\n",
    "    with open(input_seg_file,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        word_dict = { }\n",
    "        for line in lines:\n",
    "            bases = line \n",
    "            for word in bases.split():\n",
    "                word_dict.setdefault(word,0)\n",
    "                word_dict[word] += 1\n",
    "        sorted_word_dict = sorted(word_dict.items(),key = lambda d:d[1], reverse = True)\n",
    "    with open(output_stem_file,'w') as f :\n",
    "        if model==Type.label:\n",
    "            f.write('<UNK>\\t1000001\\n')\n",
    "            f.write('<PAD>\\t1000000\\n')\n",
    "        elif model == Type.feature:\n",
    "            f.write('<PAD>\\t1000000\\n')\n",
    "        for item in sorted_word_dict:\n",
    "            f.write('%s\\t%s\\n'%(item[0],item[1]))\n",
    "            \n",
    "generate_stem_file(train_folder + dbn_file_in,stem_tab_file,Type.label)\n",
    "generate_stem_file(train_folder + dbn_file_out,dbn_tab_file,Type.feature)\n",
    "generate_stem_file(train_folder + flag_file_out,flag_tab_file,Type.feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Type.label: 2>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Type.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
