{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.activations import relu\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决keras 显存问题\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "set_session(tf.Session(config=config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 10\n",
    "input_dim = 1\n",
    "MAX_LENGTH = 300 # 单个字符的长度\n",
    "output_length = 10\n",
    "output_dim = 4\n",
    "\n",
    "samples = 100\n",
    "hidden_dim = 3\n",
    "hidden_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((samples, MAX_LENGTH)) ## 100,300\n",
    "y = np.random.random((samples, MAX_LENGTH))\n",
    "z = np.random.random((samples, MAX_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_size = [embedding_length,embedding_dim,input_length]\n",
    "embedding_size = [1000,64,300]\n",
    "# hidden_size is the length of the kernel utils  = enc_units\n",
    "class EncoderRNN(Model):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2])\n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True)\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True)\n",
    "        self.bigru = Bidirectional(self.gru)\n",
    "\n",
    "    def __call__(self, en_input):\n",
    "        state_h = []\n",
    "        emb = self.embedding(en_inputs)\n",
    "        encoder_out, fwd_h1, bck_h1 = self.bigru(emb)\n",
    "        state_h.append(concatenate([fwd_h1, bck_h1]))\n",
    "        if hidden_dim>1:\n",
    "            for i in range(1,hidden_dim):\n",
    "                encoder_out, en_hidden = self.deepgru(encoder_out)\n",
    "                state_h.append(en_hidden)\n",
    "        output = encoder_out\n",
    "        hidden = state_h\n",
    "        return output, hidden\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        init_state = [tf.zeros((1, self.hidden_size)) for i in range(2)]\n",
    "        return init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(Model):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2])\n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True)\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True)\n",
    "        self.bigru = Bidirectional(self.gru)\n",
    "        \n",
    "        self.out = Dense(output_length)\n",
    "        self.softmax = Activation('softmax')\n",
    "\n",
    "    def __call__(self, de_input, hiddens):\n",
    "        state_h = []\n",
    "        emb = self.embedding(en_inputs)\n",
    "        emb = Activation('relu')(emb)\n",
    "        # !挖个坑，这里没有初始化hidden_state\n",
    "        output, fwd_h, bck_h = self.bigru(emb)\n",
    "        state_h.append(concatenate([fwd_h, bck_h]))\n",
    "        if len(hiddens)>2:\n",
    "            for hidden in hiddens[1:-1]:\n",
    "                output, de_hidden = self.deepgru(output, hidden)\n",
    "                state_h.append(de_hidden)\n",
    "        if len(hiddens)>1:\n",
    "            output, de_hidden = self.lastdeepgru(output, hidden)\n",
    "            state_h.append(de_hidden)\n",
    "        hidden = state_h\n",
    "        output = self.softmax(output)\n",
    "        print(type(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        init_state = tf.zeros((1, self.hidden_size))\n",
    "        return init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-ea0bce1d4b29>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-ea0bce1d4b29>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    self.batch_dot = Lambda(lambda [x,y]:K.batch_dot(x,y))\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AttnDecoderRNN(Model):\n",
    "    def __init__(self, embedding_size ,hidden_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2],name ='atten_embed')\n",
    "        self.attn = Dense(self.max_length,name = 'atten_attn')\n",
    "        self.attn_combine = Dense(self.hidden_size,name = 'atten_combine')\n",
    "        self.dropout = Dropout(self.dropout_p,name ='atten_dropout')\n",
    "        \n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True,name = 'atten_gru')\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True,name = 'atten_deepgru')\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True,name='atten_lastdeepgru')\n",
    "        self.bigru = Bidirectional(self.gru,name='atten_bigru')\n",
    "        self.batch_dot = Lambda(lambda x,y:K.batch_dot(x,y))\n",
    "        self.out = Dense(output_length)\n",
    "        self.softmax =Softmax(axis=-1)\n",
    "        #包装层\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __call__(self, de_input, hiddens, encoder_outputs):\n",
    "        state_h = []\n",
    "        embedded = self.embedding(de_input)\n",
    "        print(embedded.shape)\n",
    "        # TODO ; use lambda https://www.cnblogs.com/jqpy1994/p/11433746.html or  https://keras.io/zh/layers/core/\n",
    "        #embedded = K.reshape(embedded,[samples,embedding_size[1]*embedding_size[2]])\n",
    "        embedded = Reshape((1,embedding_size[1]*embedding_size[2]))(embedded)\n",
    "        print(type(embedded))\n",
    "        embedded = Lambda(lambda x:K.squeeze(x,1))(embedded)\n",
    "    \n",
    "        embedded = self.dropout(embedded) # Dim:(Batch Size , Decoder Hidden Size + Embedding Size)\n",
    "        if type(hiddens) == type(list()):\n",
    "            hidden = hiddens[-1]\n",
    "        \n",
    "        # hidden = K.reshape(hidden,[samples,self.hidden_size*2]) \n",
    "        hidden = Reshape((1,self.hidden_size*2))(hidden)\n",
    "        hidden = Lambda(lambda x:K.squeeze(x,1))(hidden)\n",
    "        concat = Concatenate(1,name='atten_concat2')([embedded, hidden])\n",
    "        # note: 从这里开始，把两个向量拼接起来    \n",
    "        attn_weights =self.softmax(\n",
    "            Dense(self.max_length)(concat))\n",
    "        \n",
    "        attn_applied = K.batch_dot(K.expand_dims(attn_weights,1),\n",
    "                                 encoder_outputs)\n",
    "        print(attn_applied.shape)\n",
    "        attn_applied =K.squeeze(attn_applied,1)\n",
    "\n",
    "        \n",
    "        output = Concatenate(1)([embedded, attn_applied])\n",
    "\n",
    "        output = self.attn_combine(output)\n",
    "        \n",
    "        output = ReLU()(output)\n",
    "        output = K.expand_dims(output,1)\n",
    "        print(type(output))\n",
    "        output, fwd_h, bck_h = self.bigru(output)\n",
    "        state_h.append(concatenate([fwd_h, bck_h]))\n",
    "        if len(hiddens)>2:\n",
    "            for hidden in hiddens[1:-1]:\n",
    "                output, de_hidden = self.deepgru(output, hidden)\n",
    "                state_h.append(de_hidden)\n",
    "        if len(hiddens)>1:\n",
    "            output, de_hidden = self.lastdeepgru(output, hidden)\n",
    "            state_h.append(de_hidden)\n",
    "        hidden = state_h\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 300, 64)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<lambda>() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d31e0e242ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0men_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mde_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0men_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mattent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mde_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0men_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-0aef61c93b6e>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, de_input, hiddens, encoder_outputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         attn_applied = self.batch_dot([Reshape((1,-1))(attn_weights),\n\u001b[0;32m---> 49\u001b[0;31m                                  encoder_outputs])\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_applied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mattn_applied\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_applied\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <lambda>() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(embedding_size,hidden_size)\n",
    "decoder = DecoderRNN(embedding_size,hidden_size)\n",
    "atten = AttnDecoderRNN(embedding_size,hidden_size)# hidden_size = 6\n",
    "\n",
    "en_inputs = Input(shape=(300,),dtype=float)\n",
    "de_inputs = Input(shape=(300,),dtype=float)\n",
    "en_output, en_hidden = encoder(en_inputs)\n",
    "de_output, de_hidden = decoder(de_inputs,en_hidden)\n",
    "attent_output = atten(de_inputs,de_hidden,en_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: Tensor(\"Squeeze_14:0\", shape=(?, 12), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8243d7a50a61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0men_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mde_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattent_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# m = model.predict(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(m.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m                                  \u001b[0;34m'the output of a Keras `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: Tensor(\"Squeeze_14:0\", shape=(?, 12), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Model([en_inputs,de_inputs], attent_output)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "# m = model.predict(z)\n",
    "# print(m.shape)\n",
    "model.fit([x,y],z,\n",
    "          epochs=20,\n",
    "          batch_size=100)\n",
    "# model.fit(x, y, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow -GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
