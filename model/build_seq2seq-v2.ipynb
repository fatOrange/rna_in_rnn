{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/home/chenzhiyuan/anaconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.activations import relu\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决keras 显存问题\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.25\n",
    "set_session(tf.Session(config=config)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 10\n",
    "input_dim = 1\n",
    "MAX_LENGTH = 300 # 单个字符的长度\n",
    "output_length = 10\n",
    "output_dim = 4\n",
    "\n",
    "samples = 100\n",
    "hidden_dim = 3\n",
    "hidden_size = 150 # must be a half of Max_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((samples, MAX_LENGTH)) ## 100,300\n",
    "y = np.random.random((samples, MAX_LENGTH))\n",
    "z = np.random.random((samples, MAX_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding_size = [embedding_length,embedding_dim,input_length]\n",
    "embedding_size = [1000,64,300]\n",
    "# hidden_size is the length of the kernel utils  = enc_units\n",
    "class EncoderRNN(Model):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2])\n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True)\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True)\n",
    "        self.bigru = Bidirectional(self.gru)\n",
    "\n",
    "    def __call__(self, en_input):\n",
    "        state_h = []\n",
    "        emb = self.embedding(en_inputs)\n",
    "        encoder_out, fwd_h1, bck_h1 = self.bigru(emb)\n",
    "        state_h.append(concatenate([fwd_h1, bck_h1]))\n",
    "        if hidden_dim>1:\n",
    "            for i in range(1,hidden_dim):\n",
    "                encoder_out, en_hidden = self.deepgru(encoder_out)\n",
    "                state_h.append(en_hidden)\n",
    "        output = encoder_out\n",
    "        hidden = state_h\n",
    "        return output, hidden\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        init_state = [tf.zeros((1, self.hidden_size)) for i in range(2)]\n",
    "        return init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(Model):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2])\n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True)\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True)\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True)\n",
    "        self.bigru = Bidirectional(self.gru)\n",
    "        \n",
    "        self.out = Dense(output_length)\n",
    "        self.softmax = Activation('softmax')\n",
    "\n",
    "    def __call__(self, de_input, hiddens):\n",
    "        state_h = []\n",
    "        emb = self.embedding(en_inputs)\n",
    "        emb = Activation('relu')(emb)\n",
    "        # !挖个坑，这里没有初始化hidden_state\n",
    "        output, fwd_h, bck_h = self.bigru(emb)\n",
    "        state_h.append(concatenate([fwd_h, bck_h]))\n",
    "        if len(hiddens)>2:\n",
    "            for hidden in hiddens[1:-1]:\n",
    "                output, de_hidden = self.deepgru(output, hidden)\n",
    "                state_h.append(de_hidden)\n",
    "        if len(hiddens)>1:\n",
    "            output, de_hidden = self.lastdeepgru(output, hidden)\n",
    "            state_h.append(de_hidden)\n",
    "        hidden = state_h\n",
    "        output = self.softmax(output)\n",
    "        print(type(output))\n",
    "        return output, hidden\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        init_state = tf.zeros((1, self.hidden_size))\n",
    "        return init_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AttnDecoderRNN(Model):\n",
    "    def __init__(self, embedding_size ,hidden_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = Embedding(embedding_size[0], embedding_size[1],input_length=embedding_size[2],name ='atten_embed')\n",
    "        self.attn = Dense(self.max_length,name = 'atten_attn')\n",
    "        self.attn_combine = Dense(self.hidden_size,name = 'atten_combine')\n",
    "        self.dropout = Dropout(self.dropout_p,name ='atten_dropout')\n",
    "        \n",
    "        self.gru = GRU(hidden_size, return_sequences=True, return_state=True,name = 'atten_gru')\n",
    "        self.deepgru = GRU(hidden_size*2, return_sequences=True, return_state=True,name = 'atten_deepgru')\n",
    "        self.lastdeepgru = GRU(hidden_size*2, return_sequences=False, return_state=True,name='atten_lastdeepgru')\n",
    "        self.bigru = Bidirectional(self.gru,name='atten_bigru')\n",
    "        self.batch_dot = Lambda(lambda layers:K.batch_dot(layers[0],layers[1]))\n",
    "        self.out = Dense(output_length)\n",
    "        self.softmax =Softmax(axis=-1)\n",
    "        #包装层\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __call__(self, de_input, hiddens, encoder_outputs):\n",
    "        state_h = []\n",
    "        embedded = self.embedding(de_input)\n",
    "        print(embedded.shape)\n",
    "        # TODO ; use lambda https://www.cnblogs.com/jqpy1994/p/11433746.html or  https://keras.io/zh/layers/core/\n",
    "        #embedded = K.reshape(embedded,[samples,embedding_size[1]*embedding_size[2]])\n",
    "        embedded = Reshape((1,embedding_size[1]*embedding_size[2]))(embedded)\n",
    "        print(type(embedded))\n",
    "        embedded = Lambda(lambda x:K.squeeze(x,1))(embedded)\n",
    "    \n",
    "        embedded = self.dropout(embedded) # Dim:(Batch Size , Decoder Hidden Size + Embedding Size)\n",
    "        if type(hiddens) == type(list()):\n",
    "            hidden = hiddens[-1]\n",
    "        \n",
    "        # hidden = K.reshape(hidden,[samples,self.hidden_size*2]) \n",
    "        hidden = Reshape((1,self.hidden_size*2))(hidden)\n",
    "        hidden = Lambda(lambda x:K.squeeze(x,1))(hidden)\n",
    "        concat = Concatenate(1,name='atten_concat2')([embedded, hidden])\n",
    "        # note: 从这里开始，把两个向量拼接起来    \n",
    "        attn_weights =self.softmax(\n",
    "            Dense(self.max_length)(concat))\n",
    "        atten_weights = Reshape((1,-1))(attn_weights)\n",
    "        attn_applied = self.batch_dot([atten_weights,encoder_outputs])\n",
    "        print(attn_applied.shape)\n",
    "        attn_applied = Lambda(lambda x:K.squeeze(x,1))(attn_applied)\n",
    "\n",
    "        \n",
    "        output = Concatenate(1)([embedded, attn_applied])\n",
    "\n",
    "        output = self.attn_combine(output)\n",
    "        \n",
    "        output = ReLU()(output)\n",
    "        output = Reshape((1,-1))(output)\n",
    "        output, fwd_h, bck_h = self.bigru(output)\n",
    "        state_h.append(concatenate([fwd_h, bck_h]))\n",
    "        if len(hiddens)>2:\n",
    "            for hidden in hiddens[1:-1]:\n",
    "                output, de_hidden = self.deepgru(output, hidden)\n",
    "                state_h.append(de_hidden)\n",
    "        if len(hiddens)>1:\n",
    "            output, de_hidden = self.lastdeepgru(output, hidden)\n",
    "            state_h.append(de_hidden)\n",
    "        hidden = state_h\n",
    "#         output = self.softmax(output)\n",
    "        output = Reshape((1,-1))(output)\n",
    "        output = TimeDistributed(Dense(MAX_LENGTH, activation='softmax'))(output)\n",
    "        output = Lambda(lambda x:K.squeeze(x,1))(output)\n",
    "        print(output.shape)\n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 300, 64)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 1, 300)\n",
      "(?, 300)\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(embedding_size,hidden_size)\n",
    "decoder = DecoderRNN(embedding_size,hidden_size)\n",
    "atten = AttnDecoderRNN(embedding_size,hidden_size)# hidden_size = 6\n",
    "\n",
    "en_inputs = Input(shape=(300,),dtype=float)\n",
    "de_inputs = Input(shape=(300,),dtype=float)\n",
    "en_output, en_hidden = encoder(en_inputs)\n",
    "attent_output,attn_hidden = atten(de_inputs,en_hidden,en_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 300, 64)      64000       input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) [(None, 300, 300), ( 193500      embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "atten_embed (Embedding)         (None, 300, 64)      64000       input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_26 (GRU)                    [(None, 300, 300), ( 540900      bidirectional_9[0][0]            \n",
      "                                                                 gru_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 1, 19200)     0           atten_embed[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 19200)        0           reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 1, 300)       0           gru_26[1][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "atten_dropout (Dropout)         (None, 19200)        0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 300)          0           reshape_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "atten_concat2 (Concatenate)     (None, 19500)        0           atten_dropout[0][0]              \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 300)          5850300     atten_concat2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_5 (Softmax)             (None, 300)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_16 (Reshape)            (None, 1, 300)       0           softmax_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 300)       0           reshape_16[0][0]                 \n",
      "                                                                 gru_26[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 300)          0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 19500)        0           atten_dropout[0][0]              \n",
      "                                                                 lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "atten_combine (Dense)           (None, 150)          2925150     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 150)          0           atten_combine[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_17 (Reshape)            (None, 1, 150)       0           re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "atten_bigru (Bidirectional)     [(None, 1, 300), (No 270900      reshape_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "atten_deepgru (GRU)             [(None, 1, 300), (No 540900      atten_bigru[0][0]                \n",
      "                                                                 gru_26[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "atten_lastdeepgru (GRU)         [(None, 300), (None, 540900      atten_deepgru[0][0]              \n",
      "                                                                 gru_26[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_18 (Reshape)            (None, 1, 300)       0           atten_lastdeepgru[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 1, 300)       90300       reshape_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 300)          0           time_distributed_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 11,080,850\n",
      "Trainable params: 11,080,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(100, 300)\n",
      "(100, 300)\n",
      "(100, 300)\n",
      "Epoch 1/20\n",
      "100/100 [==============================] - 7s 68ms/step - loss: 851.8221 - acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 851.8176 - acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 851.8127 - acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 851.8083 - acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.8038 - acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 851.7996 - acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 851.7952 - acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 851.7913 - acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 851.7873 - acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 851.7826 - acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7791 - acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7756 - acc: 0.0100\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7717 - acc: 0.0100\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 851.7676 - acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7643 - acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 851.7612 - acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 851.7576 - acc: 0.0000e+00\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 18ms/step - loss: 851.7542 - acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7509 - acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 851.7478 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fab0fc048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([en_inputs,de_inputs], attent_output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# m = model.predict(z)\n",
    "# print(m.shape)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)\n",
    "model.fit([x,y],z,\n",
    "          epochs=20,\n",
    "          batch_size=100)\n",
    "# model.fit(x, y, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow -GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
